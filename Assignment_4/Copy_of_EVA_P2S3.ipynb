{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of EVA P2S3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jofyc9OC4Qcf"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahBVnrNc3E0U"
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "plt.style.use('seaborn-white')\n",
        "import math"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crQSAaIz4SkA"
      },
      "source": [
        "# Read and process data. \n",
        "\n",
        "Download the file from this URL: https://drive.google.com/file/d/1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgOGxPDP3Wpp"
      },
      "source": [
        "data = open('text.txt', 'r').read()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeXXMLRb4kXb"
      },
      "source": [
        "Process data and calculate indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5TKeiOp4jtl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "212f0246-ca31-4bed-8163-58b05e581a79"
      },
      "source": [
        "chars = list(set(data))\n",
        "data_size, X_size = len(data), len(chars)\n",
        "print(\"Corona Virus article has %d characters, %d unique characters\" %(data_size, X_size))\n",
        "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
        "idx_to_char = {i:ch for i,ch in enumerate(chars)}"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corona Virus article has 10223 characters, 75 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C53MB135LRY"
      },
      "source": [
        "# Constants and Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfj21ORa49Ps"
      },
      "source": [
        "Hidden_Layer_size = 100 #size of the hidden layer\n",
        "Time_steps = 40 # Number of time steps (length of the sequence) used for training\n",
        "learning_rate = 1e-1 # Learning Rate\n",
        "weight_sd = 0.1 #Standard deviation of weights for initialization\n",
        "z_size = Hidden_Layer_size + X_size #Size of concatenation(H, X) vector"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdmJf4Du5uhb"
      },
      "source": [
        "# Activation Functions and Derivatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seGHei_D5FGk"
      },
      "source": [
        "def sigmoid(x): # sigmoid function\n",
        "  return # write your code here\n",
        "\n",
        "def dsigmoid(y): # derivative of sigmoid function\n",
        "  return # write your code here\n",
        "\n",
        "def tanh(x): # tanh function\n",
        "  return # write your code here\n",
        "\n",
        "def dtanh(y): # derivative of tanh\n",
        "  return # write your code here"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3khiC34keTG"
      },
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoO4rsGYkkk7"
      },
      "source": [
        "def dsigmoid(x):\n",
        "    return sigmoid(x) * (1 - sigmoid(x))"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-C5JHO1Smfn6"
      },
      "source": [
        "def tanh(x):\n",
        "  #return round((math.tan(x)),5)\n",
        "  return np.tanh(x)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBqPugZLnv5s"
      },
      "source": [
        "def dtanh(x):\n",
        "  return 1- (2*tanh(x))"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2xlSAzLkNV-",
        "outputId": "0b5cb125-e200-4b50-861d-d8aecd085821"
      },
      "source": [
        "print(sigmoid(0))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwrLMpY9kTH0",
        "outputId": "2528ea89-43a5-457c-adea-bb18a7634aef"
      },
      "source": [
        "dsigmoid(sigmoid(0))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuakedOpmb21",
        "outputId": "a790b539-0560-4286-d741-340a4e208feb"
      },
      "source": [
        " tanh(dsigmoid(sigmoid(0)))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.24472"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oQPeGHUqCH1",
        "outputId": "e47c3cf8-ee34-4cdd-e0df-57d52c16fd31"
      },
      "source": [
        "dtanh(tanh(dsigmoid(sigmoid(0)))) "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.50054"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeCvVH1v6Me-"
      },
      "source": [
        "# Quiz Question 1\n",
        "\n",
        "What is the value of sigmoid(0) calculated from  your code? (Answer up to 1 decimal point, e.g. 4.2 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "# Quiz Question 2\n",
        "\n",
        "What is the value of dsigmoid(sigmoid(0)) calculated from your code?? (Answer up to 2 decimal point, e.g. 4.29 and NOT 4.29999999, no rounding off). \n",
        "\n",
        "# Quiz Question 3\n",
        "\n",
        "What is the value of tanh(dsigmoid(sigmoid(0))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "# Quiz Question 4\n",
        "\n",
        "What is the value of dtanh(tanh(dsigmoid(sigmoid(0)))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeSVipDu8iKE"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICbWNemE6LGV"
      },
      "source": [
        "class Param:\n",
        "    def __init__(self, name, value):\n",
        "      self.name = name\n",
        "      self.v = value # parameter value\n",
        "      self.d = np.zeros_like(value) # derivative\n",
        "      self.m = np.zeros_like(value) # momentum for Adagrad"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j83pZNPE8212"
      },
      "source": [
        "We use random weights with normal distribution (0, weight_sd) for  tanh  activation function and (0.5, weight_sd) for  `sigmoid`  activation function.\n",
        "\n",
        "Biases are initialized to zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swHwLXOI9E7V"
      },
      "source": [
        "# LSTM \n",
        "You are making this network, please note f, i, c and o (also \"v\") in the image below:\n",
        "![alt text](http://blog.varunajayasiri.com/ml/lstm.svg)\n",
        "\n",
        "Please note that we are concatenating the old_hidden_vector and new_input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0DBzNY-90s5"
      },
      "source": [
        "# Quiz Question 5\n",
        "\n",
        "In the class definition below, what should be size_a, size_b, and size_c? ONLY use the variables defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFuHhqVq6Wge"
      },
      "source": [
        "size_a = Hidden_Layer_size # write your code here\n",
        "size_b = z_size# write your code here\n",
        "size_c = X_size# write your code here\n",
        "\n",
        "class Parameters:\n",
        "    def __init__(self):\n",
        "        self.W_f = Param('W_f', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_f = Param('b_f', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_i = Param('W_i', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_i = Param('b_i', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_C = Param('W_C', np.random.randn(size_a, size_b) * weight_sd)\n",
        "        self.b_C = Param('b_C', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_o = Param('W_o', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_o = Param('b_o', np.zeros((size_a, 1)))\n",
        "\n",
        "        #For final layer to predict the next character\n",
        "        self.W_v = Param('W_v', np.random.randn(X_size, size_a) * weight_sd)\n",
        "        self.b_v = Param('b_v', np.zeros((size_c, 1)))\n",
        "        \n",
        "    def all(self):\n",
        "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
        "               self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
        "        \n",
        "parameters = Parameters()"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzmfGLZt_xVs"
      },
      "source": [
        "Look at these operations which we'll be writing:\n",
        "\n",
        "**Concatenation of h and x:**\n",
        "\n",
        "$z\\:=\\:\\left[h_{t-1},\\:x\\right]$\n",
        "\n",
        "$f_t=\\sigma\\left(W_f\\cdot z\\:+\\:b_f\\:\\right)$\n",
        "\n",
        "$i_i=\\sigma\\left(W_i\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$\\overline{C_t}=\\tanh\\left(W_C\\cdot z\\:+\\:b_C\\right)$\n",
        "\n",
        "$C_t=f_t\\ast C_{t-1}+i_t\\ast \\overline{C}_t$\n",
        "\n",
        "$o_t=\\sigma\\left(W_o\\cdot z\\:+\\:b_o\\right)$\n",
        "\n",
        "$h_t=o_t\\ast\\tanh\\left(C_t\\right)$\n",
        "\n",
        "**Logits:**\n",
        "\n",
        "$v_t=W_v\\cdot h_t+b_v$\n",
        "\n",
        "**Softmax:**\n",
        "\n",
        "$\\hat{y}=softmax\\left(v_t\\right)$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bUkseNnDott"
      },
      "source": [
        "def forward(x, h_prev, C_prev, p = parameters):\n",
        "    assert x.shape == (X_size, 1)\n",
        "    assert h_prev.shape == (Hidden_Layer_size, 1)\n",
        "    assert C_prev.shape == (Hidden_Layer_size, 1)\n",
        "      \n",
        "    z = np.row_stack((h_prev, x))\n",
        "    f = sigmoid(np.dot(p.W_f.v, z) + p.b_f.v)\n",
        "    i = sigmoid(np.dot(p.W_i.v, z) + p.b_i.v)\n",
        "    C_bar = tanh(np.dot(p.W_C.v, z) + p.b_C.v)\n",
        "\n",
        "    C = f * C_prev + i * C_bar\n",
        "    o = sigmoid(np.dot(p.W_o.v, z) + p.b_o.v)\n",
        "    h = o * tanh(C)\n",
        "\n",
        "    v = np.dot(p.W_v.v, h) + p.b_v.v\n",
        "    y = np.exp(v) / np.sum(np.exp(v)) #softmax\n",
        "\n",
        "\n",
        "    return z, f, i, C_bar, C, o, h, v, y"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WClslZXftqrl",
        "outputId": "f0139025-6aa4-4f33-af9d-b373672694b3"
      },
      "source": [
        "\n",
        "## answer 6\n",
        "print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hF5bnUYyunux"
      },
      "source": [
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JJs_3zPzaAV"
      },
      "source": [
        " ## answer 7\n",
        " z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkJlnq9fziMU",
        "outputId": "cdef0cf3-5cf8-4f14-c776-f5503b803fa9"
      },
      "source": [
        "print(z.shape)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(85, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYWSImTHzjI7",
        "outputId": "dfed940d-7379-4a76-9b9b-34e0ab1c1b97"
      },
      "source": [
        "print(np.sum(z))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8-uqEHQzmzE",
        "outputId": "036ecafa-ba77-4eb3-b9dc-14e9c2e3ef56"
      },
      "source": [
        "print(np.sum(f))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZrDhZIjFpdI"
      },
      "source": [
        "You must finish the function above before you can attempt the questions below. \n",
        "\n",
        "# Quiz Question 6\n",
        "\n",
        "What is the output of 'print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))'?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV-YVl_GGiX8"
      },
      "source": [
        "# Quiz Question 7 \n",
        "\n",
        "Assuming you have fixed the forward function, run this command: \n",
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))\n",
        "\n",
        "Now, find these values:\n",
        "\n",
        "\n",
        "1.   print(z.shape)\n",
        "2.   print(np.sum(z))\n",
        "3.   print(np.sum(f))\n",
        "\n",
        "Copy and paste exact values you get in the logs into the quiz.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeSvhkqwILsG"
      },
      "source": [
        "# Backpropagation\n",
        "\n",
        "Here we are defining the backpropagation. It's too complicated, here is the whole code. (Please note that this would work only if your earlier code is perfect)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIa1jUZiGPmF"
      },
      "source": [
        "def backward(target, dh_next, dC_next, C_prev,\n",
        "             z, f, i, C_bar, C, o, h, v, y,\n",
        "             p = parameters):\n",
        "    \n",
        "    assert z.shape == (X_size + Hidden_Layer_size, 1)\n",
        "    assert v.shape == (X_size, 1)\n",
        "    assert y.shape == (X_size, 1)\n",
        "    \n",
        "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
        "        assert param.shape == (Hidden_Layer_size, 1)\n",
        "        \n",
        "    dv = np.copy(y)\n",
        "    dv[target] -= 1\n",
        "\n",
        "    p.W_v.d += np.dot(dv, h.T)\n",
        "    p.b_v.d += dv\n",
        "\n",
        "    dh = np.dot(p.W_v.v.T, dv)        \n",
        "    dh += dh_next\n",
        "    do = dh * tanh(C)\n",
        "    do = dsigmoid(o) * do\n",
        "    p.W_o.d += np.dot(do, z.T)\n",
        "    p.b_o.d += do\n",
        "\n",
        "    dC = np.copy(dC_next)\n",
        "    dC += dh * o * dtanh(tanh(C))\n",
        "    dC_bar = dC * i\n",
        "    dC_bar = dtanh(C_bar) * dC_bar\n",
        "    p.W_C.d += np.dot(dC_bar, z.T)\n",
        "    p.b_C.d += dC_bar\n",
        "\n",
        "    di = dC * C_bar\n",
        "    di = dsigmoid(i) * di\n",
        "    p.W_i.d += np.dot(di, z.T)\n",
        "    p.b_i.d += di\n",
        "\n",
        "    df = dC * C_prev\n",
        "    df = dsigmoid(f) * df\n",
        "    p.W_f.d += np.dot(df, z.T)\n",
        "    p.b_f.d += df\n",
        "\n",
        "    dz = (np.dot(p.W_f.v.T, df)\n",
        "         + np.dot(p.W_i.v.T, di)\n",
        "         + np.dot(p.W_C.v.T, dC_bar)\n",
        "         + np.dot(p.W_o.v.T, do))\n",
        "    dh_prev = dz[:Hidden_Layer_size, :]\n",
        "    dC_prev = f * dC\n",
        "    \n",
        "    return dh_prev, dC_prev"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnc7WpRkIU5S"
      },
      "source": [
        "# Forward and Backward Combined Pass\n",
        "\n",
        "Let's first clear the gradients before each backward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJWoC3U1ITf8"
      },
      "source": [
        "def clear_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.d.fill(0)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XN93UnjIgmA"
      },
      "source": [
        "Clip gradients to mitigate exploding gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LTsublxIfFl"
      },
      "source": [
        "def clip_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        np.clip(p.d, -1, 1, out=p.d)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7XUpDTWIl_Y"
      },
      "source": [
        "Calculate and store the values in forward pass. Accumulate gradients in backward pass and clip gradients to avoid exploding gradients.\n",
        "\n",
        "input, target are list of integers, with character indexes.\n",
        "h_prev is the array of initial h at  h−1  (size H x 1)\n",
        "C_prev is the array of initial C at  C−1  (size H x 1)\n",
        "Returns loss, final  hT  and  CT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQNxjTuZIia_"
      },
      "source": [
        "def forward_backward(inputs, targets, h_prev, C_prev):\n",
        "    global paramters\n",
        "    \n",
        "    # To store the values for each time step\n",
        "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
        "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
        "    v_s, y_s =  {}, {}\n",
        "    \n",
        "    # Values at t - 1\n",
        "    h_s[-1] = np.copy(h_prev)\n",
        "    C_s[-1] = np.copy(C_prev)\n",
        "    \n",
        "    loss = 0\n",
        "    # Loop through time steps\n",
        "    assert len(inputs) == Time_steps\n",
        "    for t in range(len(inputs)):\n",
        "        x_s[t] = np.zeros((X_size, 1))\n",
        "        x_s[t][inputs[t]] = 1 # Input character\n",
        "        \n",
        "        (z_s[t], f_s[t], i_s[t],\n",
        "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
        "        v_s[t], y_s[t]) = \\\n",
        "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
        "            \n",
        "        loss += -np.log(y_s[t][targets[t], 0]) # Loss for at t\n",
        "        \n",
        "    clear_gradients()\n",
        "\n",
        "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
        "    dC_next = np.zeros_like(C_s[0]) #dh from the next character\n",
        "\n",
        "    for t in reversed(range(len(inputs))):\n",
        "        # Backward pass\n",
        "        dh_next, dC_next = \\\n",
        "            backward(target = targets[t], dh_next = dh_next,\n",
        "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
        "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
        "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
        "                     y = y_s[t])\n",
        "\n",
        "    clip_gradients()\n",
        "        \n",
        "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcy5u_vRItkV"
      },
      "source": [
        "# Sample the next character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8SrtJiwIsSm"
      },
      "source": [
        "def sample(h_prev, C_prev, first_char_idx, sentence_length):\n",
        "    x = np.zeros((X_size, 1))\n",
        "    x[first_char_idx] = 1\n",
        "\n",
        "    h = h_prev\n",
        "    C = C_prev\n",
        "\n",
        "    indexes = []\n",
        "    \n",
        "    for t in range(sentence_length):\n",
        "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
        "        idx = np.random.choice(range(X_size), p=p.ravel())\n",
        "        x = np.zeros((X_size, 1))\n",
        "        x[idx] = 1\n",
        "        indexes.append(idx)\n",
        "\n",
        "    return indexes"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiWFaWLNIx_L"
      },
      "source": [
        "# Training (Adagrad)\n",
        "\n",
        "Update the graph and display a sample output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENQYU-7AIw0t"
      },
      "source": [
        "def update_status(inputs, h_prev, C_prev):\n",
        "    #initialized later\n",
        "    global plot_iter, plot_loss\n",
        "    global smooth_loss\n",
        "    \n",
        "    # Get predictions for 200 letters with current model\n",
        "\n",
        "    sample_idx = sample(h_prev, C_prev, inputs[0], 200)\n",
        "    txt = ''.join(idx_to_char[idx] for idx in sample_idx)\n",
        "\n",
        "    # Clear and plot\n",
        "    plt.plot(plot_iter, plot_loss)\n",
        "    display.clear_output(wait=True)\n",
        "    plt.show()\n",
        "\n",
        "    #Print prediction and loss\n",
        "    print(\"----\\n %s \\n----\" % (txt, ))\n",
        "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACXcASJuI73a"
      },
      "source": [
        "# Update Parameters\n",
        "\n",
        "\\begin{align}\n",
        "\\theta_i &= \\theta_i - \\eta\\frac{d\\theta_i}{\\sum dw_{\\tau}^2} \\\\\n",
        "d\\theta_i &= \\frac{\\partial L}{\\partial \\theta_i}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR08TvcjI4Pf"
      },
      "source": [
        "def update_paramters(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.m += p.d * p.d # Calculate sum of gradients\n",
        "        #print(learning_rate * dparam)\n",
        "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La9vyJ6RJLFK"
      },
      "source": [
        "To delay the keyboard interrupt to prevent the training from stopping in the middle of an iteration\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVDHbMb7JNGT"
      },
      "source": [
        "# Exponential average of loss\n",
        "# Initialize to a error of a random model\n",
        "smooth_loss = -np.log(1.0 / X_size) * Time_steps\n",
        "\n",
        "iteration, pointer = 0, 0\n",
        "\n",
        "# For the graph\n",
        "plot_iter = np.zeros((0))\n",
        "plot_loss = np.zeros((0))"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF6vS0VWJqsS"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQyNSL0iJOxH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "5dacebf8-2e18-4faf-cf82-364347af6fa9"
      },
      "source": [
        "iter = 50000\n",
        "while iter > 0:\n",
        "  # Reset\n",
        "  if pointer + Time_steps >= len(data) or iteration == 0:\n",
        "      g_h_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      g_C_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      pointer = 0\n",
        "\n",
        "\n",
        "  inputs = ([char_to_idx[ch] \n",
        "              for ch in data[pointer: pointer + Time_steps]])\n",
        "  targets = ([char_to_idx[ch] \n",
        "              for ch in data[pointer + 1: pointer + Time_steps + 1]])\n",
        "\n",
        "  loss, g_h_prev, g_C_prev = \\\n",
        "      forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
        "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
        "\n",
        "  # Print every hundred steps\n",
        "  if iteration % 100 == 0:\n",
        "      update_status(inputs, g_h_prev, g_C_prev)\n",
        "\n",
        "  update_paramters()\n",
        "\n",
        "  plot_iter = np.append(plot_iter, [iteration])\n",
        "  plot_loss = np.append(plot_loss, [loss])\n",
        "\n",
        "  pointer += Time_steps\n",
        "  iteration += 1\n",
        "  iter = iter -1"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "----\n",
            "  vn nv  Rv t  nt  rl snl  Da n hpv   l ,e l nn   v ngunvt nlvsnlf  U  lshU    unl n o 4 n   t    pr-.t  a  l,n   svf  l  R  Rl vv v lnnf?h  n l:       l s s v jRt    ,k  nvl   elol  t   nl n v    lfns \n",
            "----\n",
            "iter 49900, loss 129.083844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AKpa1BGOItQ"
      },
      "source": [
        "# Quiz Question 8\n",
        "\n",
        "Run the above code for 50000 iterations making sure that you have 100 hidden layers and time_steps is 40. What is the loss value you're seeing?"
      ]
    }
  ]
}